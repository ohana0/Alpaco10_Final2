{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'llama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm42-health/Llama3-Med42-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm42-health/Llama3-Med42-8B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dh/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:434\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m hub_kwargs \u001b[38;5;241m=\u001b[39m {name: kwargs\u001b[38;5;241m.\u001b[39mpop(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m hub_kwargs_names \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 434\u001b[0m     config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/dh/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:873\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m--> 873\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dh/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:579\u001b[0m, in \u001b[0;36m_LazyConfigMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content[key]\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    580\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[key]\n\u001b[1;32m    581\u001b[0m module_name \u001b[38;5;241m=\u001b[39m model_type_to_module_name(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'llama'"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"m42-health/Llama3-Med42-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"m42-health/Llama3-Med42-8B\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "**conversation**\n",
    "Doctor: Hello, I am Dr. Smith. Can you tell me what brings you to the hospital today?\n",
    "Patient: Yes, I have been feeling very weak and sick for the past two weeks. I have a persistent fever and dry cough.\n",
    "Doctor: I see. And how is your breathing?\n",
    "Patient: It's been shallow and rapid, especially when I am at rest. And I get severely breathless even with minor physical activities.\n",
    "Doctor: Okay. I understand. You were given physical therapy, right?\n",
    "Patient: Yes, they focused on educating me about dyspnea-relieving positions and the importance of regular mobilization and deep-breathing exercises.\n",
    "Doctor: That's good. And how did it go?\n",
    "Patient: It became evident that my anxiety from fear of dying and worries about my future was making my dyspnea worse. I was so dyspneic, anxious, and weak that I could barely walk to the toilet.\n",
    "Doctor: I see. But your physical therapist helped you with that, right?\n",
    "Patient: Yes, they listened to me, explained why I was experiencing breathlessness, and tested suitable positions to relieve my dyspnea. I felt better after the education and relaxing breathing exercises.\n",
    "Doctor: That's great to hear. Can you tell me more about the improvement?\n",
    "Patient: On day 2, my respiratory rate reduced from 30 breaths/min to 22 breaths/min and my oxygen saturation increased from 92% to 96% on 4 L/min oxygen after some deep-breathing exercises.\n",
    "Doctor: That's impressive. And how did it go after that?\n",
    "Patient: My dyspnea and anxiety started to alleviate and I regained my self-confidence. The therapy was shifted to walking and strength training, and I was able to walk 350 m without a walking aid or supplemental oxygen before my discharge home.\n",
    "Doctor: That's fantastic. You have made a great progress. I am glad to hear that.\n",
    "**request**\n",
    "Make medical letter with whole sentencse.\n",
    "Clinic summary, Treatment Plan and Management, Progress and Outcomes, Follow-Up and Monitoring is required\n",
    "answer :\n",
    "**Clinical Summary:\n",
    "Mr. X was admitted with a two-week history of fever, dry cough, and severe weakness. He had shallow, rapid breathing, especially at rest, and struggled with breathlessness even with minor activity. His anxiety worsened his breathing difficulties.\n",
    "\n",
    "**Treatment Plan and Management:\n",
    "Physical therapy focused on dyspnea-relieving positions, breathing exercises, and anxiety reduction techniques. Mr. X learned ways to manage his breathlessness and anxiety. Therapy also included education on daily mobilization.\n",
    "\n",
    "**Progress and Outcomes:\n",
    "By day 2, his respiratory rate dropped from 30 to 22 breaths per minute, and his oxygen levels improved from 92% to 96% with 4 L/min oxygen. His dyspnea and anxiety decreased, and his self-confidence improved. He could walk 350 meters without aid or supplemental oxygen at discharge.\n",
    "\n",
    "**Follow-Up and Monitoring:\n",
    "Continued breathing exercises and light physical activity at home were recommended. Regular follow-up visits will help monitor his progress. Support for anxiety management was also advised to aid recovery.e patient is advised to monitor their symptoms and keep in touch with their healthcare provider for follow-up appointments. Regular check-ins will be necessary to ensure continued progress and address any potential issues as they recover at home.\n",
    "\n",
    "**conversation**\n",
    "Doctor: Hi, Mr. X, I'm Dr. Y. How are you feeling today?\n",
    "Patient: Not too good, doctor. I've been feeling really sick lately.\n",
    "Doctor: I understand. Can you tell me what symptoms you're experiencing?\n",
    "Patient: Yes, I've been having a fever, a dry cough, and dyspnea.\n",
    "Doctor: I see. You were hospitalized due to moderate ARDS from COVID-19, is that correct?\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: During your physical therapy, we encountered some difficulties. Can you tell me more about that?\n",
    "Patient: Yes, I had trouble with position changes and deep breathing. Every time I tried to change my position or take a deep breath, I would start coughing and it would make me really short of breath.\n",
    "Doctor: I understand. To avoid rapid deterioration and respiratory failure, we instructed you to change positions very slowly and step-by-step, right?\n",
    "Patient: Yes, that's right. It took about 30 minutes to change to the prone position.\n",
    "Doctor: And I see that this approach increased your oxygen saturation, for example, on day 5 with 6 L/min of oxygen from 93% to 97%.\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: Good. We also had to adapt your breathing exercises to avoid prolonged coughing and oxygen desaturation. Can you tell me more about that?\n",
    "Patient: Yes, I was instructed to stop every deep breath before coughing and to hold my breath for better air distribution.\n",
    "Doctor: I see that you performed the breathing exercises well and managed to increase your oxygen saturation.\n",
    "Patient: Yes, I did my best.\n",
    "Doctor: You also had difficulty maintaining sufficient oxygen saturation during physical activity, is that correct?\n",
    "Patient: Yes, I did. But with close monitoring and frequent breaks, I was able to perform low-level strength and walking exercises without any significant deoxygenation.\n",
    "Doctor: I see that your exercise progression was low on days 1 to 5, but then increased daily until your hospital discharge to a rehabilitation clinic on day 10.\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: Great. I'd like to keep monitoring your progress and see how you're doing. Can you keep me updated on any changes in your symptoms?\n",
    "Patient: Yes, of course, doctor.\n",
    "Doctor: Alright, let's keep in touch. If you have any questions or concerns, don't hesitate to reach out to me.\n",
    "Patient: Thank you, doctor.\n",
    "**request**\n",
    "Make medical letter with whole sentencse.\n",
    "Clinic summary, Treatment Plan and Management, Progress and Outcomes, Follow-Up and Monitoring is required\n",
    "answer :\n",
    "**Clinic Summary:\n",
    "Mr. X was hospitalized for moderate ARDS due to COVID-19, experiencing fever, dry cough, and breathlessness. Physical therapy was challenging due to dyspnea, particularly during position changes and deep-breathing exercises.\n",
    "\n",
    "**Treatment Plan and Management:\n",
    "A gradual approach to position changes was used to prevent respiratory distress. Adjusted breathing exercises focused on controlled breaths to improve oxygen levels. Low-intensity walking and strength exercises were monitored closely to avoid deoxygenation.\n",
    "\n",
    "**Progress and Outcomes:\n",
    "By day 5, Mr. X’s oxygen saturation improved from 93% to 97% with 6 L/min of oxygen. He gradually increased activity tolerance and was discharged to rehabilitation on day 10.\n",
    "\n",
    "**Follow-Up and Monitoring:\n",
    "Regular follow-up and symptom monitoring are recommended, with continued gradual activity progression in rehabilitation.\n",
    "\n",
    "\n",
    "\n",
    "**conversation**\n",
    "Doctor: Good morning, how are you feeling today?\n",
    "Patient: Not so good, doctor. I have been feeling short of breath and my chest feels tight.\n",
    "Doctor: I see. Can you tell me more about what happened?\n",
    "Patient: Well, I tested positive for COVID-19 and was admitted to the ICU a week ago because of my oxygen levels.\n",
    "Doctor: Yes, I have your medical records here. It says you were admitted to the ICU due to oxygen desaturation of 70%. Is that correct?\n",
    "Patient: Yes, that's right.\n",
    "Doctor: And you were also experiencing worsening tachypnea and dyspnea, correct?\n",
    "Patient: Yes, I was having a hard time breathing and my breathing was getting faster.\n",
    "Doctor: I understand. Physical therapy started immediately after your ICU admission, is that correct?\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: When you were admitted to the ICU, you were a highly dyspneic patient with a high breathing frequency, correct?\n",
    "Patient: Yes, I was.\n",
    "Doctor: I see. With the help of physical therapy guidance, you managed to achieve a 135° prone position and to perform deep-breathing exercises, which resulted in an increase in your oxygen saturation from 88% to 96%, correct?\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: And after that, intensive physical therapy and positioning were continued along with 6 to 12 L/min of oxygen therapy over the next days, and intubation was avoided, correct?\n",
    "Patient: Yes, that's right.\n",
    "Doctor: I understand that the major challenges in achieving a prone position were your reduced respiratory capacity and the high risk of exacerbating your symptoms, correct?\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: But standard ICU monitoring allowed us to safely implement physical therapy at an individually adapted pace, which allowed sufficient time for convalescence, correct?\n",
    "Patient: Yes, that's right.\n",
    "Doctor: After 3 days with this regime, you were transferred to the normal ward, where physical therapists carried on your rehabilitation with walking and strength training, correct?\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: And despite your severe instability, 9 days after ICU admission, you were able to leave the hospital as a pedestrian, correct?\n",
    "Patient: Yes, that's correct.\n",
    "Doctor: That's great to hear. I'm glad you were able to recover from your illness.\n",
    "**request**\n",
    "Make medical letter with whole sentencees.\n",
    "Clinic summary, Treatment Plan and Management, Progress and Outcomes, Follow-Up and Monitoring is required.\n",
    "Please generate a summary based only on the following conversation. Do not include any information that is not clearly verified in the dialogue.\n",
    "answer :\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      3\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m      5\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.3\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 생성된 문장 디코딩\u001b[39;00m\n\u001b[1;32m     10\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=400,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    temperature=.3,\n",
    ")\n",
    "# 생성된 문장 디코딩\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
